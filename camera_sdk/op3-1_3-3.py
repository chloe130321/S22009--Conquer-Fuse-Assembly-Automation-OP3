# OP2 cameras (op2_3, op2_6) using HuarayCameraController (IMV SDK) + PLC + ConvNeXt
import os, json, cv2, torch, threading, time, traceback
import numpy as np
from datetime import datetime, timedelta  # â­ï¸ MODIFIED
import shutil  # â­ï¸ ADDED
from PIL import Image  # â­ï¸ ADDED
from typing import Tuple

from plc_socket import plc_socket
from logger import loginfo
from torchvision import transforms
from model_setup import get_model
# from inference import predict_image  # â­ï¸ REMOVED (we predict in-memory)
from camera_controller import HuarayCameraController
import torch.nn.functional as F #ç”¨æ–¼è¨ˆç®—softmax

# =========================
# PLC socket
# =========================
# â­ï¸ REMOVED: å…¨åŸŸçš„ socket_op3 å·²è¢«ç§»é™¤
# socket_op3 = plc_socket("192.168.162.160", 8501)

# =========================
# Cameras â€” IMV SDK indexes (from your check.py on THIS PC)
# Adjust index if camera order changes.
# =========================
CONFIG_PATH = "config.json"
DEFAULT_CONF_THRESHOLD = 0.80

cameras = {
    "op3_1": {
        "index": 1,
        "serial": "DA26269AAK00007",
        "base_dir": r"C:\3-1_3-3\OP3-1",
        "plc_trigger": "DM4020",   # âœ… matches op3_app.py
        "plc_result": "DM4030",
        "plc_ip": "192.168.162.160", # â­ï¸ ADDED
        "plc_port": 8501, # â­ï¸ ADDED
        # "socket": socket_op3, # â­ï¸ REMOVED
    },
    "op3_3": {
        "index": 2,
        "serial": "DA26269AAK00010",
        "base_dir": r"C:\3-1_3-3\OP3-3",
        "plc_trigger": "DM4000",   # âœ… matches op3_app.py
        "plc_result": "DM4010",
        "plc_ip": "192.168.162.160", # â­ï¸ ADDED
        "plc_port": 8501, # â­ï¸ ADDED
        # "socket": socket_op3, # â­ï¸ REMOVED
    },
}

def load_config():
    if not os.path.exists(CONFIG_PATH):
        print(f"âš ï¸ Config file {CONFIG_PATH} not found! Using defaults.")
        return {"confidence_threshold": DEFAULT_CONF_THRESHOLD, "models": {}}
    
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            cfg = json.load(f)
            print(f"âœ… Config loaded: Threshold={cfg.get('confidence_threshold')}")
            return cfg
    except Exception as e:
        print(f"âŒ Failed to load config: {e}")
        return {"confidence_threshold": DEFAULT_CONF_THRESHOLD, "models": {}}

# ç¨‹å¼å•Ÿå‹•æ™‚å…ˆè®€å–ä¸€æ¬¡é…ç½®
APP_CONFIG = load_config()
CONF_THRESHOLD = APP_CONFIG.get("confidence_threshold", DEFAULT_CONF_THRESHOLD)
MODEL_BASE_DIR = APP_CONFIG.get("model_base_dir", r"C:\3-1_3-3\model")

# å¾ config å–å¾—æª”åï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨é è¨­å€¼æˆ–å ±éŒ¯
model_name_op3_1 = APP_CONFIG.get("models", {}).get("op3_1", "default_model_1.pth")
model_name_op3_3 = APP_CONFIG.get("models", {}).get("op3_3", "default_model_2.pth")

CLASSIFY_CFG = {
    "op3_1": {
        "type": "double",
        "model_path": os.path.join(MODEL_BASE_DIR, model_name_op3_1),
        "class_names": ["ok", "ng"],
        # "crop_ratio": 0.4,  <-- åˆªé™¤é€™è¡Œï¼Œä¸éœ€è¦äº†
        "crops": [
            # ç¬¬ä¸€å€‹è£åˆ‡æ¡† (ä¾‹å¦‚ï¼šå·¦é‚Šçš„ç‰©ä»¶)
            {"x": 250, "y": 580, "w": 180, "h": 130}, 
            # ç¬¬äºŒå€‹è£åˆ‡æ¡† (ä¾‹å¦‚ï¼šå³é‚Šçš„ç‰©ä»¶)
            {"x": 680, "y": 410, "w": 160, "h": 130},
        ],
    },
    "op3_3": {
        "type": "double",
        "model_path": os.path.join(MODEL_BASE_DIR, model_name_op3_3),
        "class_names": ["ok", "ng"],
        # "crop_ratio": 0.5, <-- åˆªé™¤é€™è¡Œ
        "crops": [
            # ç¬¬ä¸€å€‹è£åˆ‡æ¡†
            {"x": 340, "y": 580, "w": 170, "h": 130},
            # ç¬¬äºŒå€‹è£åˆ‡æ¡†
            {"x": 790, "y": 700, "w": 190, "h": 140},
        ],
    },
}




VAL_TRANSFORM = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
])

# =========================
# Load models once per unique path
# =========================
_MODEL_CACHE = {}
for cam, cfg in CLASSIFY_CFG.items():
    path = cfg["model_path"]; names = cfg["class_names"]
    try:
        model = get_model(num_classes=len(names))
        state = torch.load(path, map_location="cuda:0" if torch.cuda.is_available() else "cpu")
        model.load_state_dict(state)
        model.eval()
        _MODEL_CACHE[path] = model
        loginfo("ConvNeXtInit", f"[{cam}] Loaded model: {path}")
    except Exception as e:
        loginfo("ConvNeXtInit", f"[{cam}] FAILED to load {path}: {e}")

# =========================
# Helpers
# =========================

def cleanup_old_folders(base_dir, days_to_keep):
    """â­ï¸ ADDED: åˆªé™¤è¶…éæŒ‡å®šå¤©æ•¸çš„èˆŠè³‡æ–™å¤¾ (æ ¼å¼ YYYY-MM-DD)"""
    if not os.path.exists(base_dir):
        return  # æ ¹ç›®éŒ„ä¸å­˜åœ¨ï¼Œç„¡éœ€æ¸…ç†
    try:
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        for folder_name in os.listdir(base_dir):
            folder_path = os.path.join(base_dir, folder_name)
            
            if os.path.isdir(folder_path):
                try:
                    folder_date = datetime.strptime(folder_name, '%Y-%m-%d')
                    if folder_date.date() < cutoff_date.date():
                        shutil.rmtree(folder_path)
                        loginfo("Cleanup", f"[{os.path.basename(base_dir)}] å·²åˆªé™¤èˆŠè³‡æ–™å¤¾: {folder_path}")
                except ValueError:
                    pass
                except Exception as e:
                    loginfo("Cleanup", f"åˆªé™¤è³‡æ–™å¤¾ {folder_path} æ™‚å‡ºéŒ¯: {e}")
    except Exception as e:
        loginfo("Cleanup", f"æ¸…ç†ç¨‹åº {base_dir} å‡ºéŒ¯: {e}")


def ensure_dirs(base_dir: str) -> Tuple[str, str]:
    date_dir = datetime.now().strftime("%Y-%m-%d")
    full_dir  = os.path.join(base_dir, date_dir)
    os.makedirs(full_dir, exist_ok=True)
    return date_dir, full_dir

def _imwrite_png(path: str, img: np.ndarray) -> bool:
    if img is None or img.size == 0:
        return False
    img = np.ascontiguousarray(img)
    ok = cv2.imwrite(path, img)
    if not ok:
        print(f"âŒ imwrite failed â†’ {path} (shape={None if img is None else img.shape}, dtype={None if img is None else img.dtype})")
    return ok

def save_full_frame(image_bgr: np.ndarray, base_dir: str, date_dir: str, base_name: str) -> Tuple[bool, str]:
    path = os.path.join(base_dir, date_dir, f"{base_name}.png")
    ok = _imwrite_png(path, image_bgr)
    return ok, path

def _center_shift_crop(img_bgr: np.ndarray, crop_ratio: float, dx: int, dy: int) -> np.ndarray:
    h, w = img_bgr.shape[:2]
    cw, ch = max(1, int(w * crop_ratio)), max(1, int(h * crop_ratio))
    cx, cy = w // 2 + int(dx), h // 2 + int(dy)
    x1 = max(0, cx - cw // 2)
    y1 = max(0, cy - ch // 2)
    x2 = min(w, x1 + cw)
    y2 = min(h, y1 + ch)
    x1 = max(0, x2 - cw)
    y1 = max(0, y2 - ch)
    return img_bgr[y1:y2, x1:x2]

def _predict_in_memory(cv2_img_bgr: np.ndarray, model, class_names, transform, threshold: float) -> str:
    """â­ï¸ MODIFIED: æ–°å¢ threshold åƒæ•¸"""
    try:
        img_rgb = cv2.cvtColor(cv2_img_bgr, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(img_rgb)
        input_tensor = transform(pil_image)
        input_batch = input_tensor.unsqueeze(0)
        device = next(model.parameters()).device
        input_batch = input_batch.to(device)
        
        with torch.no_grad():
            output = model(input_batch)
            
            # â­ï¸ MODIFIED: è½‰æ›ç‚ºæ©Ÿç‡ (0~1)
            probs = F.softmax(output, dim=1) 
            
            # å–å¾—æœ€å¤§æ©Ÿç‡èˆ‡å°æ‡‰çš„é¡åˆ¥ç´¢å¼•
            top_p, top_class_idx = probs.topk(1, dim=1)
            
            conf_score = top_p.item()
            pred_index = top_class_idx.item()
            pred_class = class_names[pred_index]

            # â­ï¸ ä¿¡å¿ƒåº¦åˆ¤æ–·é‚è¼¯
            # å¦‚æœé æ¸¬æ˜¯ OKï¼Œä½†ä¿¡å¿ƒåº¦ä¸è¶³ï¼Œå¼·åˆ¶è½‰ç‚º NG (æˆ– unknown)
            # å¦‚æœé æ¸¬æœ¬ä¾†å°±æ˜¯ NGï¼Œä¿¡å¿ƒåº¦ä½ä¹Ÿé‚„æ˜¯ NG
            if conf_score < threshold:
                loginfo("ConvNeXt", f"Low confidence: {conf_score:.4f} < {threshold}. Pred: {pred_class} -> Force NG")
                return "ng" # ä¿¡å¿ƒä¸è¶³è¦–ç‚º NG
            
        return pred_class
        
    except Exception as e:
        loginfo("ConvNeXt", f"_predict_in_memory failed: {e}")
        return "unknown"


def classify_frame(camera_name, image_bgr, base_dir, date_dir, base_name):
    cfg = CLASSIFY_CFG.get(camera_name)
    if not cfg:
        return None
    model = _MODEL_CACHE.get(cfg["model_path"])
    names = cfg["class_names"]
    if model is None or not names:
        loginfo("ConvNeXt", f"[{camera_name}] Model or class names missing.")
        return None

    out = {"camera": camera_name, "crops": [], "final": None}
    results = []
    
    # â­ï¸ é€™è£¡è¦ä½¿ç”¨æœ€æ–°çš„ CONF_THRESHOLD (å¦‚æœæƒ³è¦æ”¯æ´ç†±æ›´æ–°ï¼Œå¯ä»¥åœ¨é€™è£¡é‡æ–° reload config)
    current_thresh = CONF_THRESHOLD 

    for i, off in enumerate(cfg.get("crops", []), 1):
        crop_img = _center_shift_crop(image_bgr, cfg["crop_ratio"], off["dx"], off["dy"])
        
        # â­ï¸ MODIFIED: å‚³å…¥ current_thresh
        pred = _predict_in_memory(crop_img, model, names, VAL_TRANSFORM, current_thresh)
        
        out["crops"].append({"pred": pred})
        results.append(pred)

    if len(results) == 2 and results[0] == "ok" and results[1] == "ok":
        out["final"] = "ok"
    else:
        out["final"] = "ng"

    return out


def safe_send(sock, addr, val, suffix=".U"):
    """â­ï¸ MODIFIED: å¢åŠ å° sock is None çš„æª¢æŸ¥"""
    if sock is None:
        print(f"âŒ PLC send skipped (socket is None) {addr} <= {val}")
        return
    try:
        sock.Send(addr, val, suffix)
        print(f"ğŸ“¤ PLC {addr} <= {val}")
    except Exception as e:
        print(f"âŒ PLC send failed {addr} <= {val}: {e}")
        raise # â­ï¸ æ‹‹å‡ºç•°å¸¸ï¼Œè®“ camera_task çŸ¥é“é€£ç·šå·²ä¸­æ–·

# =========================
# Connect cameras
# =========================
camera_objects = {}
for name, cfg in cameras.items():
    os.makedirs(cfg["base_dir"], exist_ok=True)
    cam = HuarayCameraController()
    if cam.connect(device_index=cfg["index"]):
        camera_objects[name] = cam
        print(f"âœ… Camera {name} CONNECTED (Index {cfg['index']}, Serial {cfg['serial']}) â†’ saving to {cfg['base_dir']}")
        ensure_dirs(cfg["base_dir"])   # create today's dir
    else:
        print(f"âŒ Camera {name} FAILED to connect")

# =========================
# Thread loop
# =========================
def camera_task(cam: HuarayCameraController, plc_trigger, plc_result, name, plc_ip, plc_port, base_dir):
    """â­ï¸ MODIFIED: 
    - æ¥æ”¶ plc_ip, plc_port (ä¸å†æ¥æ”¶ sock)
    - å…§éƒ¨ç®¡ç† socket é€£ç·šå’Œé‡é€£
    - å…§éƒ¨å‘¼å« cleanup_old_folders
    """
    socket = None
    last_trig = None

    def _connect_plc():
        """(Re)connects the PLC."""
        print(f"[{name}]  attempting to connect PLC {plc_ip}...")
        try:
            sock = plc_socket(plc_ip, plc_port)
            print(f"[{name}] PLC connected.")
            return sock
        except Exception as e:
            print(f"[{name}] PLC connection failed: {e}")
            return None

    # å•Ÿå‹•æ™‚é€²è¡Œç¬¬ä¸€æ¬¡é€£ç·š
    socket = _connect_plc()

    while True:
        # â­ï¸ 1. æ¯æ¬¡è¿´åœˆå…ˆåŸ·è¡Œæ¸…ç†
        cleanup_old_folders(base_dir, 5) 
        
        # â­ï¸ 2. æª¢æŸ¥ PLC é€£ç·š
        if socket is None:
            print(f"[{name}] PLC disconnected. Retrying in 5s...")
            time.sleep(5)
            socket = _connect_plc()
            continue # é€²å…¥ä¸‹ä¸€æ¬¡è¿´åœˆ

        # â­ï¸ 3. è®€å– PLC ç‹€æ…‹ (å¸¶æœ‰é‡é€£é‚è¼¯)
        try:
            raw = socket.Get(plc_trigger, ".D")
            trig = int(raw.strip().splitlines()[0])
        except Exception as e:
            print(f"âŒ [{name}] PLC Get error: {e}. Marking for reconnect.")
            socket = None # â­ï¸ æ¨™è¨˜ç‚ºæ–·ç·šï¼Œä¸‹æ¬¡è¿´åœˆé‡é€£
            continue

        # â­ï¸ 4. æª¢æŸ¥è§¸ç™¼ (ä¿æŒä¸è®Š)
        if trig != last_trig:
            print(f"[{name}] Trigger={trig}{' â†’ Capturing' if trig == 1 else ' â†’ Waiting'}")
            last_trig = trig

        if trig != 1:
            time.sleep(0.5) # â­ï¸ åœ¨ç­‰å¾…æ™‚ sleepï¼Œé¿å…ç©ºè½‰
            continue

        # â­ï¸ 5. ä¸»é‚è¼¯ (å¸¶æœ‰é‡é€£é‚è¼¯)
        try:
            if not cam.start_grabbing():
                raise RuntimeError("start_grabbing() failed")
            time.sleep(0.1)   # small settle time

            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = f"{name}_{ts}"

            frame = cam.grab_image_numpy(timeout_ms=3000)
            cam.stop_grabbing()
            if frame is None:
                raise RuntimeError("No frame")

            if frame.ndim == 3 and frame.shape[2] == 3:
                frame = frame[:, :, ::-1]

            date_dir, full_dir = ensure_dirs(base_dir)
            
            # â­ï¸ æ­¥é©Ÿ 1: å…ˆåˆ†é¡
            cls_out = classify_frame(name, frame, base_dir, date_dir, base_name)
            
            if cls_out:
                final = cls_out["final"]
                preds = [c["pred"] for c in cls_out["crops"]]
                print(f"ğŸ§  [{name}] crop_preds={preds} â†’ FINAL={final.upper()}")

                # â­ï¸ æ­¥é©Ÿ 2: ç™¼é€æœ€çµ‚çµæœ (1=OK, 3=NG)
                safe_send(socket, plc_result, 1 if final == "ok" else 3, ".U")

                # â­ï¸ æ­¥é©Ÿ 3: åªåœ¨ NG æ™‚å„²å­˜
                if final == "ng":
                    loginfo("CameraTask", f"[{name}] Result: NG. Saving annotated full frame.")
                    
                    # å„²å­˜å¸¶æœ‰æ¨™è¨˜çš„å®Œæ•´åŸåœ–
                    annotated_full = frame.copy()
                    cv2.putText(annotated_full, "NG", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 15)
                    cv2.putText(annotated_full, name, (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 255), 15)
                    
                    full_ng_name = f"{base_name}_NG"
                    ok, full_path = save_full_frame(annotated_full, base_dir, date_dir, full_ng_name)
                    if ok:
                        print(f"ğŸ“¸ [{name}] Saved NG full frame: {full_path}")
                else:
                    loginfo("CameraTask", f"[{name}] Result: OK. No images saved.")
                    
            else:
                print(f"âš ï¸  [{name}] classification skipped (no config/model)")
                safe_send(socket, plc_result, 3, ".U") # åˆ†é¡å¤±æ•—ï¼Œç™¼é€ NG

            # â­ï¸ æ­¥é©Ÿ 4: reset trigger
            time.sleep(0.3)
            safe_send(socket, plc_trigger, 0, ".U")

        except Exception as e:
            # â­ï¸ é—œéµï¼šä¸»é‚è¼¯ï¼ˆåŒ…å« safe_sendï¼‰å‡ºéŒ¯
            print(f"âŒ [{name}] MainTask ERROR: {traceback.format_exc()}")
            loginfo("CameraTask", f"[{name}] ERROR: {e}")
            try:
                cam.stop_grabbing()
            except Exception:
                pass
            
            # å˜—è©¦ç™¼é€éŒ¯èª¤è¨Šè™Ÿ
            safe_send(socket, plc_result, 3, ".U") 
            safe_send(socket, plc_trigger, 0, ".U")
            
            socket = None # â­ï¸ ç¢ºä¿æ¨™è¨˜ç‚ºæ–·ç·š

# =========================
# Start threads
# =========================
threads = []
for name, cfg in cameras.items():
    cam = camera_objects.get(name)
    if not cam:
        print(f"â­ï¸  {name} not connected; skipping.")
        continue
    
    # â­ï¸ MODIFIED: æ›´æ–°å‚³å…¥çš„åƒæ•¸
    t = threading.Thread(
        target=camera_task,
        args=(
            cam, 
            cfg["plc_trigger"], 
            cfg["plc_result"], 
            name, 
            cfg["plc_ip"],     # â­ï¸ NEW
            cfg["plc_port"],   # â­ï¸ NEW
            cfg["base_dir"]
        ),
        daemon=True
    )
    t.start()
    threads.append(t)
    print(f"ğŸš€ Started thread for {name}")

for t in threads:
    t.join()
